{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rojinadeuja/Multi-Layer-Perceptron/blob/master/NLP_Tasks_Using_Flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPG-3RZ5cmG8",
        "colab_type": "text"
      },
      "source": [
        "## Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvTeFx7dbWQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1GhyH4k9C4uPRnMAMKhJYOqa-V9Tqt4q8' ### File ID ###\n",
        "data = drive.CreateFile({'id': file_id})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcXyvXmtcuNP",
        "colab_type": "text"
      },
      "source": [
        "## Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuwRSz7QbbHH",
        "colab_type": "code",
        "outputId": "18afa5a0-772d-4c53-9d73-36916c6477b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "data = pd.read_csv(io.StringIO(data.GetContentString())) \n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>user  user thanks for  lyft credit i can t us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>factsguide  society now     motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  label                                              tweet\n",
              "0           0    0.0    user when a father is dysfunctional and is s...\n",
              "1           1    0.0   user  user thanks for  lyft credit i can t us...\n",
              "2           2    0.0                                bihday your majesty\n",
              "3           3    0.0   model   i love u take with u all the time in ...\n",
              "4           4    0.0             factsguide  society now     motivation"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr_iVN0-cyiL",
        "colab_type": "text"
      },
      "source": [
        "## Load Flair and PyTorch Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuur7QFs6zHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove all rows that have label as NaN\n",
        "data = data[data['tweet'].notna()]\n",
        "# Sample only a 1000 rows\n",
        "data= data.sample(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "748l2anX95OM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "66c2bd5a-2c9f-45aa-e651-41f16f225fcb"
      },
      "source": [
        "data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20113</th>\n",
              "      <td>20113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>user really   that  user are sponsoring  use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30280</th>\n",
              "      <td>30280</td>\n",
              "      <td>0.0</td>\n",
              "      <td>user irresponsible parents creating irrespons...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18091</th>\n",
              "      <td>18091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>user he make me happy     myangel      me  s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29124</th>\n",
              "      <td>29124</td>\n",
              "      <td>0.0</td>\n",
              "      <td>i am thankful for love   thankful  positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8341</th>\n",
              "      <td>8341</td>\n",
              "      <td>0.0</td>\n",
              "      <td>user you make me and all the  user proud  we ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7947</th>\n",
              "      <td>7947</td>\n",
              "      <td>0.0</td>\n",
              "      <td>kkinetic band goin down            warner chap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29074</th>\n",
              "      <td>29074</td>\n",
              "      <td>0.0</td>\n",
              "      <td>user  msrlm   is it too soon for me to sta t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2794</th>\n",
              "      <td>2794</td>\n",
              "      <td>0.0</td>\n",
              "      <td>always be    effluent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14403</th>\n",
              "      <td>14403</td>\n",
              "      <td>0.0</td>\n",
              "      <td>be hpy n healthy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17673</th>\n",
              "      <td>17673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>user take me away</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  label                                              tweet\n",
              "20113       20113    0.0    user really   that  user are sponsoring  use...\n",
              "30280       30280    0.0   user irresponsible parents creating irrespons...\n",
              "18091       18091    0.0    user he make me happy     myangel      me  s...\n",
              "29124       29124    0.0   i am thankful for love   thankful  positive     \n",
              "8341         8341    0.0   user you make me and all the  user proud  we ...\n",
              "...           ...    ...                                                ...\n",
              "7947         7947    0.0  kkinetic band goin down            warner chap...\n",
              "29074       29074    0.0    user  msrlm   is it too soon for me to sta t...\n",
              "2794         2794    0.0                             always be    effluent \n",
              "14403       14403    0.0                                  be hpy n healthy \n",
              "17673       17673    0.0                               user take me away   \n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TufwOC6XcEPj",
        "colab_type": "code",
        "outputId": "cf8d696c-9407-4843-a3b3-dff6f2637ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "# !pip install flair\n",
        "!pip install --upgrade git+https://github.com/flairNLP/flair.git\n",
        "import flair"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-65kwtqft\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-65kwtqft\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: transformers>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2.9.1)\n",
            "Requirement already satisfied, skipping upgrade: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.5.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: pytest>=5.3.2 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (5.4.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.5.10)\n",
            "Requirement already satisfied, skipping upgrade: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.2.10)\n",
            "Requirement already satisfied, skipping upgrade: langdetect in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.1.90)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair==0.4.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (8.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (0.13.1)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (20.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (0.1.9)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.4.5) (0.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.5) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.6.0->flair==0.4.5) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (1.13.10)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.4.5) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (1.16.10)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.10->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.15.2)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.4.5-cp36-none-any.whl size=148505 sha256=a4591e489c6a823d80c5b2a12df06efc6dcb5ad03702cfe874d9798a53b57d98\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oi5b6rrg/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
            "Successfully built flair\n",
            "Installing collected packages: flair\n",
            "  Found existing installation: flair 0.4.5\n",
            "    Uninstalling flair-0.4.5:\n",
            "      Successfully uninstalled flair-0.4.5\n",
            "Successfully installed flair-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NilCgmRwcJ_r",
        "colab_type": "code",
        "outputId": "e80a992c-8c1c-4b97-8c4a-aa39f17fed93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from flair.data import Sentence\n",
        "# Create a sentence\n",
        "sentence = Sentence('Blogs of Analytics Vidhya are Awesome.')\n",
        "# Print the sentence to see what’s in it\n",
        "print(sentence) # A Sentence is essentially a list of tokens"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"Blogs of Analytics Vidhya are Awesome.\"   [− Tokens: 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKKEcNIecWz-",
        "colab_type": "code",
        "outputId": "cbf233be-2d75-49f2-c3c7-c7e8cbb347fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Extract only the tweet column from the dataframe\n",
        "text = data['tweet'] \n",
        "# Create a list fo the tweets called txt\n",
        "txt = text.tolist()\n",
        "print(txt[:10])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['  user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction     run', ' user  user thanks for  lyft credit i can t use cause they don t offer wheelchair vans in pdx      disapointed  getthanked', '  bihday your majesty', ' model   i love u take with u all the time in ur                                      ', ' factsguide  society now     motivation', '      huge fan fare and big talking before they leave  chaos and pay disputes when they get there   allshowandnogo  ', '  user camping tomorrow  user  user  user  user  user  user  user danny   ', 'the next school year is the year for exams      can t think about that       school  exams    hate  imagine  actorslife  revolutionschool  girl', 'we won    love the land     allin  cavs  champions  cleveland  clevelandcavaliers      ', '  user  user welcome here    i m   it s so  gr    ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uG6OIRFgCkV",
        "colab_type": "text"
      },
      "source": [
        "## Word Embedding Using Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRDEdhTFccp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the embeddings\n",
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.embeddings import CharacterEmbeddings\n",
        "from flair.embeddings import StackedEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "from flair.embeddings import BertEmbeddings\n",
        "from flair.embeddings import ELMoEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "\n",
        "# Initialise embeddings (un-comment to use others)\n",
        "#glove_embedding = WordEmbeddings('glove')\n",
        "#character_embeddings = CharacterEmbeddings()\n",
        "flair_forward  = FlairEmbeddings('news-forward-fast')\n",
        "flair_backward = FlairEmbeddings('news-backward-fast')\n",
        "#bert_embedding = BertEmbedding()\n",
        "#elmo_embedding = ElmoEmbedding()\n",
        "\n",
        "# Stack the embeddings : Combine multiple embeddings into a powerful word representation model without much complexity\n",
        "stacked_embeddings = StackedEmbeddings( embeddings = [ \n",
        "                                                       flair_forward, \n",
        "                                                       flair_backward\n",
        "                                                      ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unJiRuWwz2Of",
        "colab_type": "text"
      },
      "source": [
        "## Test stacked embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWQmHRIpzzJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "fdf50a28-411d-49d4-dbf7-e2404c79f3d6"
      },
      "source": [
        "# Create a sentence\n",
        "sentence = Sentence('These blogs are awesome.')\n",
        "# Embed words in the sentence\n",
        "stacked_embeddings.embed(sentence)\n",
        "for token in sentence:\n",
        "  print(token.embedding)\n",
        "# Print type and size of the embedding\n",
        "print(type(token.embedding))\n",
        "print(token.embedding.size()[0])\n",
        "z = token.embedding.size()[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 3.8988e-03, -3.7598e-05, -3.4552e-03,  ...,  1.1473e-09,\n",
            "        -7.2948e-07,  5.2823e-02])\n",
            "tensor([-4.9989e-02, -6.4013e-05,  6.3951e-03,  ...,  3.6644e-09,\n",
            "         4.5787e-07, -6.5868e-02])\n",
            "tensor([-4.9550e-03, -1.2693e-04,  2.1048e-02,  ...,  1.2971e-07,\n",
            "         4.0299e-07, -1.2174e-01])\n",
            "tensor([-7.3077e-05, -5.1575e-06,  2.3907e-02,  ...,  2.4966e-08,\n",
            "         6.5300e-09, -1.1079e-01])\n",
            "<class 'torch.Tensor'>\n",
            "2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EweZm51ngAYG",
        "colab_type": "text"
      },
      "source": [
        "## Vectorizing the text\n",
        "We will be using two approaches for vectorizing the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37R-Yp5d5pLx",
        "colab_type": "text"
      },
      "source": [
        "## Mean of Word Embeddings within a Tweet\n",
        "In this approach, for each sentence we do the following:\n",
        "1. Generate word embeddings for each word\n",
        "2. Calculate mean of the embeddings for each word to get embedding of the sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOeSGkfV50Ln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "04b2ac44-739f-4ade-ba31-8a90d1631c3b"
      },
      "source": [
        "from tqdm import tqdm # Progress bar to track progress\n",
        "# Create a tensor for storing the sentence embeddings\n",
        "s = torch.zeros(0, z)\n",
        "\n",
        "# Iterate over each sentence\n",
        "for tweet in tqdm(txt):\n",
        "  # Empty tensor for words\n",
        "  w = torch.zeros(0, z)\n",
        "  sentence = Sentence(tweet)\n",
        "  stacked_embeddings.embed(sentence)\n",
        "  # Iterate over each word\n",
        "  for token in sentence:\n",
        "    # Store the embeddings of each word in a sentence\n",
        "    w = torch.cat((w, token.embedding.view(-1, z)), 0)\n",
        "    # Store the embeddings of each sentence ie. all words\n",
        "    s = torch.cat((s, w.mean(dim = 0).view(-1, z)), 0)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5dd6bdf6c466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;31m# Progress bar to track progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Create a tensor for storing the sentence embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Iterate over each sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toGutLHmGuWy",
        "colab_type": "text"
      },
      "source": [
        "## Document Embedding: Vectorizing the entire Tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ05fRZ87OoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from flair.embeddings import DocumentPoolEmbeddings\n",
        "\n",
        "# # Initialize the document embeddings, mode =mean\n",
        "# document_embeddings = DocumentPoolEmbeddings([\n",
        "#                                               flair_backward,\n",
        "#                                               flair_forward\n",
        "# ])\n",
        "\n",
        "# # Store the size of embedding\n",
        "# z = sentence.embedding.size()[0]\n",
        "\n",
        "# # Vectorize the text\n",
        "# # Create a tensor for storing sentence embeddings\n",
        "# s = torch.zeros(0, z)\n",
        "\n",
        "# # Iterate over the sentences\n",
        "# for tweet in tqdm(txt):\n",
        "#   sentence = Sentence(tweet)\n",
        "#   document_embeddings.embed(sentence)\n",
        "#   # Adding Document embeddings to list\n",
        "#   s = torch.cat((s, sentence.embedding.view(-1,z)), 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK4cugOHIt39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence.embedding.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS6tTutgPWPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}