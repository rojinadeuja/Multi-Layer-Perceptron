{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rojinadeuja/Multi-Layer-Perceptron/blob/master/NLP_Tasks_Using_Flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPG-3RZ5cmG8",
        "colab_type": "text"
      },
      "source": [
        "## Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvTeFx7dbWQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1GhyH4k9C4uPRnMAMKhJYOqa-V9Tqt4q8' ### File ID ###\n",
        "data = drive.CreateFile({'id': file_id})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcXyvXmtcuNP",
        "colab_type": "text"
      },
      "source": [
        "## Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuwRSz7QbbHH",
        "colab_type": "code",
        "outputId": "be6c7fed-ea07-4240-9c79-a48551bb56fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "data1 = drive.CreateFile({'id': file_id})\n",
        "data1 = pd.read_csv(io.StringIO(data1.GetContentString())) \n",
        "data1.head()\n",
        "print(data1.shape)\n",
        "data1 = data1[data1['label'].notna()]\n",
        "print(data1.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49159, 3)\n",
            "(31962, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr_iVN0-cyiL",
        "colab_type": "text"
      },
      "source": [
        "## Load Flair and PyTorch Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuur7QFs6zHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove all rows that have label as NaN\n",
        "data = data[data['label'].notna()]\n",
        "# Sample only a 1000 rows\n",
        "data= data.sample(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "748l2anX95OM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "295c532a-726a-46d6-e884-3d8c4a93a72b"
      },
      "source": [
        "# Check data dimensions\n",
        "data.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TufwOC6XcEPj",
        "colab_type": "code",
        "outputId": "bee7e4d4-efcb-4526-d93b-0d3cd983d6d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "# !pip install flair\n",
        "!pip install --upgrade git+https://github.com/flairNLP/flair.git\n",
        "import flair"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-0ezsm5fk\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-0ezsm5fk\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (3.6.0)\n",
            "Collecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/f9/9f2b6c672c8f8bb87a4c1bd52c1b57213627b035305aad745d015b2a62ae/pytest-5.4.2-py3-none-any.whl (247kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 2.8MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 48.6MB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.8.7)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Collecting transformers>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (1.5.0+cu101)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (0.1.2)\n",
            "Collecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.5) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.5) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (20.3)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (0.1.9)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair==0.4.5) (8.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair==0.4.5) (0.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.5) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (0.7)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 39.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (3.0.12)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.6.0->flair==0.4.5) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair==0.4.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.5) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (1.13.10)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair==0.4.5) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.6.0->flair==0.4.5) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.6.0->flair==0.4.5) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair==0.4.5) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (1.16.10)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.10->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.5) (0.15.2)\n",
            "Building wheels for collected packages: flair\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.4.5-cp36-none-any.whl size=148505 sha256=b7f11378af7bcd11b7e1ffb9e217dbbbfbd0dd521385f1db8c63ae2a9e9bcd36\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gi263y5r/wheels/84/82/73/d2b3b59b7be74ea05f2c6d64132efe27df52daffb47d1dc7bb\n",
            "Successfully built flair\n",
            "Building wheels for collected packages: mpld3, langdetect, segtok, sqlitedict, sacremoses\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=fc8d72c16b8bdf8fb708e5ccafb524fd2d8199e80f4f745a8045812563a4ed76\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=adb1cfbad9e7c98f6867c2ae7b6668c1ac5fe42998232052ed11c7db850b1bd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25020 sha256=05bc89201b3db0b9c95f729254ff827d398b942124659cc206e50b239fc71278\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=1bd13fd5c3e1ba0533feb6d8c11d2e30a771754da98391390060b29235671619\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=03c72f188635425afe1d6acf6fb29d94de6b1149fcb5544c36950c7d338eeab7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built mpld3 langdetect segtok sqlitedict sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pluggy, pytest, mpld3, langdetect, segtok, deprecated, sentencepiece, sacremoses, tokenizers, transformers, sqlitedict, bpemb, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.10 flair-0.4.5 langdetect-1.0.8 mpld3-0.3 pluggy-0.13.1 pytest-5.4.2 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.6.0 tokenizers-0.7.0 transformers-2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NilCgmRwcJ_r",
        "colab_type": "code",
        "outputId": "460cd5e3-b8de-442e-c19f-7945cc2e62e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from flair.data import Sentence\n",
        "# Create a sentence\n",
        "sentence = Sentence('Blogs of Analytics Vidhya are Awesome.')\n",
        "# Print the sentence to see what’s in it\n",
        "print(sentence) # A Sentence is essentially a list of tokens"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: \"Blogs of Analytics Vidhya are Awesome.\"   [− Tokens: 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKKEcNIecWz-",
        "colab_type": "code",
        "outputId": "3e831915-cc2e-4445-91b4-4a18c18b570d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Extract only the tweet column from the dataframe\n",
        "text = data['tweet'] \n",
        "# Create a list fo the tweets called txt\n",
        "txt = text.tolist()\n",
        "print(txt[:10])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['  user really   that  user are sponsoring  user this year  thegamefair  ', ' user irresponsible parents creating irresponsible kids who don t care abt laws     ', '  user he make me happy     myangel      me  selfie  blonde  picoftheday  beard  beards  boy    ', 'i am thankful for love   thankful  positive     ', ' user you make me and all the  user proud  we feel better when you   makeamericahate     thank a rube today  alwaystrump', 'tonight s the night     mtg  eternalmasters  boosterdraft     joshua tree games ', 'use the power of your mind to  heal your body      altwaystoheal  healthy is     ', 'work in progress for  summer       newstyles  inspiration  finebyme  photooftheday    ', 'couldn t be happier with her         her  loveislove  love  gay      ', ' coffeelover   attack bull game  d  do you really think that his head was empty around the city  each side i ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uG6OIRFgCkV",
        "colab_type": "text"
      },
      "source": [
        "## Word Embedding Using Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRDEdhTFccp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "c988ca63-dd95-4093-a2a5-1af803d35e22"
      },
      "source": [
        "# Import the embeddings\n",
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.embeddings import CharacterEmbeddings\n",
        "from flair.embeddings import StackedEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "from flair.embeddings import BertEmbeddings\n",
        "from flair.embeddings import ELMoEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "\n",
        "# Initialise embeddings (un-comment to use others)\n",
        "#glove_embedding = WordEmbeddings('glove')\n",
        "#character_embeddings = CharacterEmbeddings()\n",
        "flair_forward  = FlairEmbeddings('news-forward-fast')\n",
        "flair_backward = FlairEmbeddings('news-backward-fast')\n",
        "#bert_embedding = BertEmbedding()\n",
        "#elmo_embedding = ElmoEmbedding()\n",
        "\n",
        "# Stack the embeddings : Combine multiple embeddings into a powerful word representation model without much complexity\n",
        "stacked_embeddings = StackedEmbeddings( embeddings = [ \n",
        "                                                       flair_forward, \n",
        "                                                       flair_backward\n",
        "                                                      ])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 16:03:21,792 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpm__6bk_b\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:01<00:00, 12939282.50B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 16:03:23,847 copying /tmp/tmpm__6bk_b to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2020-05-21 16:03:23,876 removing temp file /tmp/tmpm__6bk_b\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 16:03:24,885 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp_q76m2fe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:01<00:00, 13045611.71B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-21 16:03:26,910 copying /tmp/tmp_q76m2fe to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2020-05-21 16:03:26,938 removing temp file /tmp/tmp_q76m2fe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unJiRuWwz2Of",
        "colab_type": "text"
      },
      "source": [
        "## Test stacked embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWQmHRIpzzJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "7cc684b8-c660-4681-9133-ba3355d690ca"
      },
      "source": [
        "# Create a sentence\n",
        "sentence = Sentence('These blogs are awesome.')\n",
        "# Embed words in the sentence\n",
        "stacked_embeddings.embed(sentence)\n",
        "for token in sentence:\n",
        "  print(token.embedding)\n",
        "# Print type and size of the embedding\n",
        "print(type(token.embedding))\n",
        "print(token.embedding.size()[0])\n",
        "z = token.embedding.size()[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 3.8988e-03, -3.7598e-05, -3.4552e-03,  ...,  1.1473e-09,\n",
            "        -7.2948e-07,  5.2823e-02])\n",
            "tensor([-4.9989e-02, -6.4013e-05,  6.3951e-03,  ...,  3.6644e-09,\n",
            "         4.5787e-07, -6.5868e-02])\n",
            "tensor([-4.9550e-03, -1.2693e-04,  2.1048e-02,  ...,  1.2971e-07,\n",
            "         4.0299e-07, -1.2174e-01])\n",
            "tensor([-7.3077e-05, -5.1575e-06,  2.3907e-02,  ...,  2.4966e-08,\n",
            "         6.5300e-09, -1.1079e-01])\n",
            "<class 'torch.Tensor'>\n",
            "2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EweZm51ngAYG",
        "colab_type": "text"
      },
      "source": [
        "## Vectorizing the text\n",
        "We will be using two approaches for vectorizing the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37R-Yp5d5pLx",
        "colab_type": "text"
      },
      "source": [
        "## Mean of Word Embeddings within a Tweet\n",
        "In this approach, for each sentence we do the following:\n",
        "1. Generate word embeddings for each word\n",
        "2. Calculate mean of the embeddings for each word to get embedding of the sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOeSGkfV50Ln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "179521d6-5a03-4904-dc13-eabf2bac0458"
      },
      "source": [
        "from tqdm import tqdm # Progress bar to track progress\n",
        "# Create a tensor for storing the sentence embeddings\n",
        "s = torch.zeros(0, z)\n",
        "\n",
        "# Iterate over each sentence\n",
        "for tweet in tqdm(txt):\n",
        "  # Empty tensor for words\n",
        "  w = torch.zeros(0, z)\n",
        "  sentence = Sentence(tweet)\n",
        "  stacked_embeddings.embed(sentence)\n",
        "  # Iterate over each word\n",
        "  for token in sentence:\n",
        "    # Store the embeddings of each word in a sentence\n",
        "    w = torch.cat((w, token.embedding.view(-1, z)), 0)\n",
        "    # Store the embeddings of each sentence ie. all words\n",
        "    s = torch.cat((s, w.mean(dim = 0).view(-1, z)), 0)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [05:18<00:00,  3.14it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toGutLHmGuWy",
        "colab_type": "text"
      },
      "source": [
        "## Document Embedding: Vectorizing the entire Tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ05fRZ87OoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from flair.embeddings import DocumentPoolEmbeddings\n",
        "\n",
        "# # Initialize the document embeddings, mode =mean\n",
        "# document_embeddings = DocumentPoolEmbeddings([\n",
        "#                                               flair_backward,\n",
        "#                                               flair_forward\n",
        "# ])\n",
        "\n",
        "# # Store the size of embedding\n",
        "# z = sentence.embedding.size()[0]\n",
        "\n",
        "# # Vectorize the text\n",
        "# # Create a tensor for storing sentence embeddings\n",
        "# s = torch.zeros(0, z)\n",
        "\n",
        "# # Iterate over the sentences\n",
        "# for tweet in tqdm(txt):\n",
        "#   sentence = Sentence(tweet)\n",
        "#   document_embeddings.embed(sentence)\n",
        "#   # Adding Document embeddings to list\n",
        "#   s = torch.cat((s, sentence.embedding.view(-1,z)), 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu7FD-Y4BNyd",
        "colab_type": "text"
      },
      "source": [
        "## Partition the data into Train/Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS6tTutgPWPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = s.numpy() # Convert the tensor to a numpy array\n",
        "\n",
        "# Test Set\n",
        "test = X[1000:, :]\n",
        "train = X[:1000, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlNcRkgmBzRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58d66488-e4ec-43f4-c3bb-eedde484edbc"
      },
      "source": [
        "# Check the dimensions for the train dataset\n",
        "train.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f84kMTqUB0ZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20741863-fabb-4d6e-987f-13eb9aa1d644"
      },
      "source": [
        "# Check the dimensions for the train dataset\n",
        "test.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12022, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDz53HFJB1eX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df82330b-e0af-436a-b138-769a25a75e52"
      },
      "source": [
        "# Extract labels of the training set\n",
        "target = data['label'][data['label'].isnull()==False].values\n",
        "target.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKi-XYWTDeE5",
        "colab_type": "text"
      },
      "source": [
        "## Build the Model and Define Custome Evaluator (for F1 Score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-FquIzVCSOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define custom F1 evaluator for XGBoost\n",
        "def custom_eval(preds, dtrain):\n",
        "  labels = dtrain.get_label().astype(np.int)\n",
        "  preds = (preds >= 0.3).astype(np.int)\n",
        "  return[('f1_score', f1_score(labels, preds))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZODDwO5WCTLi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3a93f2a-c62e-4af4-bd86-2adde19650b5"
      },
      "source": [
        "# Build the XGBoost model\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Split the train and test set\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train, target, random_state=42, test_size=0.3)\n",
        "\n",
        "# XGBoost compatible data\n",
        "dtrain = xgb.DMatrix(x_train, y_train)\n",
        "dvalid = xgb.DMatrix(x_valid, label = y_valid)\n",
        "\n",
        "# Define the parameters\n",
        "params = {\n",
        "    'colsample': 0.9,\n",
        "    'colsample_bytree': 0.5,\n",
        "    'eta': 0.1,\n",
        "    'max_depth': 8,\n",
        "    'min_child_weight': 6,\n",
        "    'objective': 'binary:logistic',\n",
        "    'subsample': 0.9\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "xgb_model = xgb.train(params, dtrain, feval=custom_eval, num_boost_round=1000, maximize=True, \n",
        "                      evals=[(dvalid, \"Validation\")], early_stopping_rounds=100)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tValidation-error:0.053333\tValidation-f1_score:0.101266\n",
            "Multiple eval metrics have been passed: 'Validation-f1_score' will be used for early stopping.\n",
            "\n",
            "Will train until Validation-f1_score hasn't improved in 100 rounds.\n",
            "[1]\tValidation-error:0.053333\tValidation-f1_score:0.101266\n",
            "[2]\tValidation-error:0.053333\tValidation-f1_score:0.101266\n",
            "[3]\tValidation-error:0.053333\tValidation-f1_score:0.101266\n",
            "[4]\tValidation-error:0.053333\tValidation-f1_score:0.101266\n",
            "[5]\tValidation-error:0.053333\tValidation-f1_score:0.075472\n",
            "[6]\tValidation-error:0.053333\tValidation-f1_score:0.060606\n",
            "[7]\tValidation-error:0.053333\tValidation-f1_score:0.061538\n",
            "[8]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[9]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[10]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[11]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[12]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[13]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[14]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[15]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[16]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[17]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[18]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[19]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[20]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[21]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[22]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[23]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[24]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[25]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[26]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[27]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[28]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[29]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[30]\tValidation-error:0.053333\tValidation-f1_score:0\n",
            "[31]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[32]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[33]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[34]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[35]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[36]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[37]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[38]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[39]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[40]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[41]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[42]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[43]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[44]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[45]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[46]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[47]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[48]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[49]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[50]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[51]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[52]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[53]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[54]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[55]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[56]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[57]\tValidation-error:0.056667\tValidation-f1_score:0\n",
            "[58]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[59]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[60]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[61]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[62]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[63]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[64]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[65]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[66]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[67]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[68]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[69]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[70]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[71]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[72]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[73]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[74]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[75]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[76]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[77]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[78]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[79]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[80]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[81]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[82]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[83]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[84]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[85]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[86]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[87]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[88]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[89]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[90]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[91]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[92]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[93]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[94]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[95]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[96]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[97]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[98]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[99]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "[100]\tValidation-error:0.06\tValidation-f1_score:0\n",
            "Stopping. Best iteration:\n",
            "[0]\tValidation-error:0.053333\tValidation-f1_score:0.101266\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDjSpbsbGwi4",
        "colab_type": "text"
      },
      "source": [
        "## Make Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hulTcxRSFvzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reformatting test set for XGB\n",
        "dtest = xgb.DMatrix(test)\n",
        "\n",
        "# Prediction\n",
        "predict = xgb_model.predict(dtest) # predicting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byW2vvSpGfT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm4pTHfEGigd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}